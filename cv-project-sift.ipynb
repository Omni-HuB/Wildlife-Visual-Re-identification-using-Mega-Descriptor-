{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install wildlife-datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install wildlife-tools","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install timm","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nimport numpy as np\nfrom wildlife_datasets.datasets import MacaqueFaces\nfrom wildlife_tools.data import WildlifeDataset\nimport torchvision.transforms as T\nfrom wildlife_datasets import datasets, splits\nfrom wildlife_tools.features import DeepFeatures\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_tools.inference import KnnClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nimport numpy as np\nfrom PIL import Image\nimport torchvision.transforms as T\nimport cv2  # Import OpenCV for SIFT\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nfrom wildlife_tools.data import WildlifeDataset\nfrom wildlife_datasets.datasets import MacaqueFaces\n\nfrom wildlife_datasets import datasets, splits\nfrom wildlife_tools.features import DeepFeatures\nfrom wildlife_tools.similarity import CosineSimilarity\nfrom wildlife_tools.inference import KnnClassifier\nfrom wildlife_tools.features import SIFTFeatures\n\n\nfrom wildlife_tools.data import WildlifeDataset, SplitMetadata\nfrom wildlife_tools.features import SIFTFeatures\nfrom wildlife_tools.similarity import MatchDescriptors\nfrom wildlife_tools.inference import KnnClassifier\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CowDataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.CowDataset.get_data('../data/CowDataset')\n\n# Load dataset metadata\nmetadata_CZoo = datasets.CowDataset('../data/CowDataset')\ntransform = T.Compose([T.Resize([224, 224]), T.ToTensor(), T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\ndataset = WildlifeDataset(metadata_CZoo.df, metadata_CZoo.root, transform=transform)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.CowDataset.get_data('../data/CowDataset')\n\n# Load dataset metadata\nmetadata_CZoo = datasets.CowDataset('../data/CowDataset')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_CZoo.df, metadata_CZoo.root, transform=transform)\ndataset_database_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[100:], metadata_CZoo.root, transform=transform)\ndataset_query_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[:100], metadata_CZoo.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_CZoo = SIFTFeatures()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_CZoo, database_CZoo = extractor_CZoo(dataset_query_CZoo), extractor_CZoo(dataset_database_CZoo)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'First 5 query features shape: {[i.shape for i in query_CZoo[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_CZoo[:5]]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.8])\nsim = similarity(query_CZoo, database_CZoo)[0.8]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_CZoo = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npredictions_CZoo = classifier_CZoo(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_CZoo)\naccuracy_CZoo = np.mean(dataset_query_CZoo.labels_string == predictions_CZoo)\nprint(\"Accuracy on MacaqueFaces data: {:.2f}%\".format(accuracy_CZoo * 100))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_CZoo.labels_string)\n\nacc = sum(preds == dataset_query_CZoo.labels_string) / len(dataset_query_CZoo.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CZoo Dataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.CZoo.get_data('../data/CZoo')\n\n# Load dataset metadata\nmetadata_CZoo = datasets.CZoo('../data/CZoo')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_CZoo.df, metadata_CZoo.root, transform=transform)\ndataset_database_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[100:], metadata_CZoo.root, transform=transform)\ndataset_query_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[:100], metadata_CZoo.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_CZoo = SIFTFeatures()\n\nquery_CZoo, database_CZoo = extractor_CZoo(dataset_query_CZoo), extractor_CZoo(dataset_database_CZoo)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_CZoo[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_CZoo[:5]]}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.8])\nsim = similarity(query_CZoo, database_CZoo)[0.8]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_CZoo = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npredictions_CZoo = classifier_CZoo(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_CZoo)\naccuracy_CZoo = np.mean(dataset_query_CZoo.labels_string == predictions_CZoo)\nprint(\"Accuracy on CZoo data: {:.2f}%\".format(accuracy_CZoo * 100))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_CZoo.labels_string)\n\nacc = sum(preds == dataset_query_CZoo.labels_string) / len(dataset_query_CZoo.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**IPanda50 Dataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.IPanda50.get_data('../data/IPanda50')\n# Load dataset metadata\nmetadata = datasets.IPanda50('../data/IPanda50')\ntransform = T.Compose([T.Resize([224, 224]), T.ToTensor(), T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\ndataset = WildlifeDataset(metadata.df, metadata.root, transform=transform)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.IPanda50.get_data('../data/Ipanda50')\n\n# Load dataset metadata\nmetadata_Ipanda50 = datasets.IPanda50('../data/Ipanda50')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_Ipanda50.df, metadata_Ipanda50.root, transform=transform)\ndataset_database_Ipanda50 = WildlifeDataset(metadata_Ipanda50.df.iloc[100:], metadata_Ipanda50.root, transform=transform)\ndataset_query_Ipanda50 = WildlifeDataset(metadata_Ipanda50.df.iloc[:100], metadata_Ipanda50.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_Ipanda50 = SIFTFeatures()\n\nquery_Ipanda50, database_Ipanda50 = extractor_Ipanda50(dataset_query_Ipanda50), extractor_Ipanda50(dataset_database_Ipanda50)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_Ipanda50[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_Ipanda50[:5]]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.8])\nsim = similarity(query_Ipanda50, database_Ipanda50)[0.8]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_Ipanda50 = KnnClassifier(k=1, database_labels=dataset_database_Ipanda50.labels_string)\npredictions_Ipanda50 = classifier_Ipanda50(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_Ipanda50)\naccuracy_Ipanda50 = np.mean(dataset_query_Ipanda50.labels_string == predictions_Ipanda50)\nprint(\"Accuracy on Ipanda50 data: {:.2f}%\".format(accuracy_Ipanda50 * 100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_Ipanda50.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_Ipanda50.labels_string)\n\nacc = sum(preds == dataset_query_Ipanda50.labels_string) / len(dataset_query_Ipanda50.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LionData Dataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.LionData.get_data('../data/LionData')\n\n# Load dataset metadata\nmetadata_LionData = datasets.LionData('../data/LionData')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_LionData.df, metadata_LionData.root, transform=transform)\ndataset_database_LionData = WildlifeDataset(metadata_LionData.df.iloc[100:], metadata_LionData.root, transform=transform)\ndataset_query_LionData = WildlifeDataset(metadata_LionData.df.iloc[:100], metadata_LionData.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_LionData = SIFTFeatures()\n\nquery_LionData, database_LionData = extractor_LionData(dataset_query_LionData), extractor_LionData(dataset_database_LionData)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_LionData[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_LionData[:5]]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.6])\nsim = similarity(query_LionData, database_LionData)[0.6]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_LionData = KnnClassifier(k=1, database_labels=dataset_database_LionData.labels_string)\npredictions_LionData = classifier_LionData(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_LionData)\naccuracy_LionData = np.mean(dataset_query_LionData.labels_string == predictions_LionData)\nprint(\"Accuracy on LionData data: {:.2f}%\".format(accuracy_LionData * 100))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_LionData.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_LionData.labels_string)\n\nacc = sum(preds == dataset_query_LionData.labels_string) / len(dataset_query_LionData.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MacaqueFaces Dataset**\n","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.MacaqueFaces.get_data('../data/MacaqueFaces')\n\n# Load dataset metadata\nmetadata_MacaqueFaces = datasets.MacaqueFaces('../data/MacaqueFaces')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_MacaqueFaces.df, metadata_MacaqueFaces.root, transform=transform)\n\ndataset_database_MacaqueFaces = WildlifeDataset(metadata_MacaqueFaces.df.iloc[100:], metadata_MacaqueFaces.root, transform=transform)\ndataset_query_MacaqueFaces = WildlifeDataset(metadata_MacaqueFaces.df.iloc[:100], metadata_MacaqueFaces.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_MacaqueFaces = SIFTFeatures()\n\nquery_MacaqueFaces, database_MacaqueFaces = extractor_MacaqueFaces(dataset_query_MacaqueFaces), extractor_MacaqueFaces(dataset_database_MacaqueFaces)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_MacaqueFaces[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_MacaqueFaces[:5]]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.7])\nsim = similarity(query_MacaqueFaces, database_MacaqueFaces)[0.7]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_MacaqueFaces = KnnClassifier(k=1, database_labels=dataset_database_MacaqueFaces.labels_string)\npredictions_MacaqueFaces = classifier_MacaqueFaces(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_MacaqueFaces)\naccuracy_MacaqueFaces = np.mean(dataset_query_MacaqueFaces.labels_string == predictions_MacaqueFaces)\nprint(\"Accuracy on MacaqueFaces data: {:.2f}%\".format(accuracy_MacaqueFaces * 100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_MacaqueFaces.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_MacaqueFaces.labels_string)\n\nacc = sum(preds == dataset_query_MacaqueFaces.labels_string) / len(dataset_query_MacaqueFaces.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NyalaDataSet Dataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.NyalaData.get_data('../data/NyalaData')\n\n# Load dataset metadata\nmetadata_NyalaData = datasets.NyalaData('../data/NyalaData')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_NyalaData.df, metadata_NyalaData.root, transform=transform)\ndataset_database_NyalaData = WildlifeDataset(metadata_NyalaData.df.iloc[100:], metadata_NyalaData.root, transform=transform)\ndataset_query_NyalaData = WildlifeDataset(metadata_NyalaData.df.iloc[:100], metadata_NyalaData.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_NyalaData = SIFTFeatures()\n\nquery_NyalaData, database_NyalaData = extractor_NyalaData(dataset_query_NyalaData), extractor_NyalaData(dataset_database_NyalaData)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_NyalaData[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_NyalaData[:5]]}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.7])\nsim = similarity(query_NyalaData, database_NyalaData)[0.7]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_NyalaData = KnnClassifier(k=1, database_labels=dataset_database_NyalaData.labels_string)\npredictions_NyalaData = classifier_NyalaData(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_NyalaData)\naccuracy_NyalaData = np.mean(dataset_query_NyalaData.labels_string == predictions_NyalaData)\nprint(\"Accuracy on NyalaData data: {:.2f}%\".format(accuracy_NyalaData * 100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_NyalaData.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_NyalaData.labels_string)\n\nacc = sum(preds == dataset_query_NyalaData.labels_string) / len(dataset_query_NyalaData.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**StripeSpotter Dataset**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.StripeSpotter.get_data('../data/StripeSpotter')\n\n# Load dataset metadata\nmetadata_StripeSpotter = datasets.StripeSpotter('../data/StripeSpotter')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_StripeSpotter.df, metadata_StripeSpotter.root, transform=transform)\ndataset_database_StripeSpotter = WildlifeDataset(metadata_StripeSpotter.df.iloc[100:], metadata_StripeSpotter.root, transform=transform)\ndataset_query_StripeSpotter = WildlifeDataset(metadata_StripeSpotter.df.iloc[:100], metadata_StripeSpotter.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_StripeSpotter = SIFTFeatures()\n\nquery_StripeSpotter, database_StripeSpotter = extractor_StripeSpotter(dataset_query_StripeSpotter), extractor_StripeSpotter(dataset_database_StripeSpotter)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_StripeSpotter[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_StripeSpotter[:5]]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.7])\nsim = similarity(query_StripeSpotter, database_StripeSpotter)[0.7]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_StripeSpotter = KnnClassifier(k=1, database_labels=dataset_database_StripeSpotter.labels_string)\npredictions_StripeSpotter = classifier_StripeSpotter(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_StripeSpotter)\naccuracy_StripeSpotter = np.mean(dataset_query_StripeSpotter.labels_string == predictions_StripeSpotter)\nprint(\"Accuracy on StripeSpotter data: {:.2f}%\".format(accuracy_StripeSpotter * 100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_StripeSpotter.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_StripeSpotter.labels_string)\n\nacc = sum(preds == dataset_query_StripeSpotter.labels_string) / len(dataset_query_StripeSpotter.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ON NEW UNSEEN DATASETS**","metadata":{}},{"cell_type":"markdown","source":"**DogFaceNet**","metadata":{}},{"cell_type":"code","source":"# Download dataset (if not already downloaded)\ndatasets.DogFaceNet.get_data('../data/DogFaceNet')\n\n# Load dataset metadata\nmetadata_DogFaceNet = datasets.DogFaceNet('../data/DogFaceNet')\n\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_DogFaceNet.df, metadata_DogFaceNet.root, transform=transform)\ndataset_database_DogFaceNet = WildlifeDataset(metadata_DogFaceNet.df.iloc[100:], metadata_DogFaceNet.root, transform=transform)\ndataset_query_DogFaceNet = WildlifeDataset(metadata_DogFaceNet.df.iloc[:100], metadata_DogFaceNet.root, transform=transform)\n\n# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_DogFaceNet = SIFTFeatures()\n\nquery_DogFaceNet, database_DogFaceNet = extractor_DogFaceNet(dataset_query_DogFaceNet), extractor_DogFaceNet(dataset_database_DogFaceNet)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_DogFaceNet[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_DogFaceNet[:5]]}')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.7])\nsim = similarity(query_DogFaceNet, database_DogFaceNet)[0.7]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n\n\nclassifier_DogFaceNet = KnnClassifier(k=1, database_labels=dataset_database_DogFaceNet.labels_string)\npredictions_DogFaceNet = classifier_DogFaceNet(sim)\n\nprint(\"Predictions for 100 test Images:-\\n\",predictions_DogFaceNet)\naccuracy_DogFaceNet = np.mean(dataset_query_DogFaceNet.labels_string == predictions_DogFaceNet)\nprint(\"Accuracy on DogFaceNet data: {:.2f}%\".format(accuracy_DogFaceNet * 100))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_DogFaceNet.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_DogFaceNet.labels_string)\n\nacc = sum(preds == dataset_query_DogFaceNet.labels_string) / len(dataset_query_DogFaceNet.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}