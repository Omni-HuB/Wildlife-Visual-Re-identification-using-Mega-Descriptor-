{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shariq20220/cv-project-superpointloss?scriptVersionId=191383736\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%pip install wildlife-datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-06T08:24:35.992927Z","iopub.execute_input":"2024-08-06T08:24:35.99337Z","iopub.status.idle":"2024-08-06T08:24:53.910156Z","shell.execute_reply.started":"2024-08-06T08:24:35.993336Z","shell.execute_reply":"2024-08-06T08:24:53.908517Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting wildlife-datasets\n  Downloading wildlife_datasets-1.0.4-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (1.26.4)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (2.2.2)\nRequirement already satisfied: tqdm>=4.62.3 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (4.66.4)\nRequirement already satisfied: opencv-python>=4.5.5.62 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (9.5.0)\nRequirement already satisfied: scikit-learn>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (1.2.2)\nRequirement already satisfied: matplotlib>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (3.7.5)\nCollecting gdown (from wildlife-datasets)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets) (1.6.14)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->wildlife-datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->wildlife-datasets) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-datasets) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-datasets) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-datasets) (3.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->wildlife-datasets) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->wildlife-datasets) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown->wildlife-datasets) (2.32.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets) (2024.7.4)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets) (6.1.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->wildlife-datasets) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->wildlife-datasets) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->wildlife-datasets) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->wildlife-datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->wildlife-datasets) (3.6)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->wildlife-datasets) (1.7.1)\nDownloading wildlife_datasets-1.0.4-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown, wildlife-datasets\nSuccessfully installed gdown-5.2.0 wildlife-datasets-1.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install wildlife-tools","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:38:22.483407Z","iopub.execute_input":"2024-08-06T08:38:22.484064Z","iopub.status.idle":"2024-08-06T08:38:42.722299Z","shell.execute_reply.started":"2024-08-06T08:38:22.484005Z","shell.execute_reply":"2024-08-06T08:38:42.72055Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting wildlife-tools\n  Downloading wildlife_tools-0.0.9-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (2.1.2+cpu)\nRequirement already satisfied: timm>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (1.0.7)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (1.26.4)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (2.2.2)\nRequirement already satisfied: tqdm>=4.62.3 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (4.66.4)\nRequirement already satisfied: opencv-python>=4.5.5.62 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (4.10.0.84)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (9.5.0)\nRequirement already satisfied: scikit-learn>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (1.2.2)\nCollecting pycocotools (from wildlife-tools)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (2.15.1)\nCollecting pytorch-metric-learning (from wildlife-tools)\n  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: transformers>=4.30.2 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (4.42.3)\nRequirement already satisfied: wildlife-datasets>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (1.0.4)\nRequirement already satisfied: kornia>=0.6.12 in /opt/conda/lib/python3.10/site-packages (from wildlife-tools) (0.7.3)\nCollecting faiss-gpu (from wildlife-tools)\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: kornia-rs>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from kornia>=0.6.12->wildlife-tools) (0.1.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from kornia>=0.6.12->wildlife-tools) (21.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->wildlife-tools) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->wildlife-tools) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->wildlife-tools) (2023.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-tools) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-tools) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->wildlife-tools) (3.2.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm>=0.9.2->wildlife-tools) (0.16.2+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm>=0.9.2->wildlife-tools) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm>=0.9.2->wildlife-tools) (0.23.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm>=0.9.2->wildlife-tools) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.1->wildlife-tools) (2024.5.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2->wildlife-tools) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2->wildlife-tools) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.30.2->wildlife-tools) (0.19.1)\nRequirement already satisfied: matplotlib>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets>=0.3.4->wildlife-tools) (3.7.5)\nRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets>=0.3.4->wildlife-tools) (5.2.0)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from wildlife-datasets>=0.3.4->wildlife-tools) (1.6.14)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (1.60.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (3.5.2)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->wildlife-tools) (3.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->wildlife-tools) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->wildlife-tools) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->wildlife-tools) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->wildlife-tools) (1.3.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.5.1->wildlife-datasets>=0.3.4->wildlife-tools) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2->wildlife-tools) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2->wildlife-tools) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2->wildlife-tools) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.30.2->wildlife-tools) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->wildlife-tools) (2.1.3)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->wildlife-datasets>=0.3.4->wildlife-tools) (4.12.2)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets>=0.3.4->wildlife-tools) (8.0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->wildlife-datasets>=0.3.4->wildlife-tools) (6.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.0.1->wildlife-tools) (1.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->wildlife-tools) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->wildlife-tools) (3.2.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->wildlife-datasets>=0.3.4->wildlife-tools) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->wildlife-datasets>=0.3.4->wildlife-tools) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->wildlife-datasets>=0.3.4->wildlife-tools) (1.3)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->wildlife-datasets>=0.3.4->wildlife-tools) (1.7.1)\nDownloading wildlife_tools-0.0.9-py3-none-any.whl (25 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu, pytorch-metric-learning, pycocotools, wildlife-tools\nSuccessfully installed faiss-gpu-1.7.2 pycocotools-2.0.8 pytorch-metric-learning-2.6.0 wildlife-tools-0.0.9\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:38:42.725126Z","iopub.execute_input":"2024-08-06T08:38:42.725662Z","iopub.status.idle":"2024-08-06T08:38:57.551614Z","shell.execute_reply.started":"2024-08-06T08:38:42.725613Z","shell.execute_reply":"2024-08-06T08:38:57.550269Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (1.0.7)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.23.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# %BANNER_BEGIN%\n# ---------------------------------------------------------------------\n# %COPYRIGHT_BEGIN%\n#\n#  Magic Leap, Inc. (\"COMPANY\") CONFIDENTIAL\n#\n#  Unpublished Copyright (c) 2020\n#  Magic Leap, Inc., All Rights Reserved.\n#\n# NOTICE:  All information contained herein is, and remains the property\n# of COMPANY. The intellectual and technical concepts contained herein\n# are proprietary to COMPANY and may be covered by U.S. and Foreign\n# Patents, patents in process, and are protected by trade secret or\n# copyright law.  Dissemination of this information or reproduction of\n# this material is strictly forbidden unless prior written permission is\n# obtained from COMPANY.  Access to the source code contained herein is\n# hereby forbidden to anyone except current COMPANY employees, managers\n# or contractors who have executed Confidentiality and Non-disclosure\n# agreements explicitly covering such access.\n#\n# The copyright notice above does not evidence any actual or intended\n# publication or disclosure  of  this source code, which includes\n# information that is confidential and/or proprietary, and is a trade\n# secret, of  COMPANY.   ANY REPRODUCTION, MODIFICATION, DISTRIBUTION,\n# PUBLIC  PERFORMANCE, OR PUBLIC DISPLAY OF OR THROUGH USE  OF THIS\n# SOURCE CODE  WITHOUT THE EXPRESS WRITTEN CONSENT OF COMPANY IS\n# STRICTLY PROHIBITED, AND IN VIOLATION OF APPLICABLE LAWS AND\n# INTERNATIONAL TREATIES.  THE RECEIPT OR POSSESSION OF  THIS SOURCE\n# CODE AND/OR RELATED INFORMATION DOES NOT CONVEY OR IMPLY ANY RIGHTS\n# TO REPRODUCE, DISCLOSE OR DISTRIBUTE ITS CONTENTS, OR TO MANUFACTURE,\n# USE, OR SELL ANYTHING THAT IT  MAY DESCRIBE, IN WHOLE OR IN PART.\n#\n# %COPYRIGHT_END%\n# ----------------------------------------------------------------------\n# %AUTHORS_BEGIN%\n#\n#  Originating Authors: Paul-Edouard Sarlin\n#\n# %AUTHORS_END%\n# --------------------------------------------------------------------*/\n# %BANNER_END%\n\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\n\n\ndef simple_nms(scores, nms_radius: int):\n    \"\"\"Fast Non-maximum suppression to remove nearby points.\"\"\"\n    assert nms_radius >= 0\n\n    def max_pool(x):\n        return torch.nn.functional.max_pool2d(\n            x, kernel_size=nms_radius * 2 + 1, stride=1, padding=nms_radius\n        )\n\n    zeros = torch.zeros_like(scores)\n    max_mask = scores == max_pool(scores)\n    for _ in range(2):\n        supp_mask = max_pool(max_mask.float()) > 0\n        supp_scores = torch.where(supp_mask, zeros, scores)\n        new_max_mask = supp_scores == max_pool(supp_scores)\n        max_mask = max_mask | (new_max_mask & (~supp_mask))\n    return torch.where(max_mask, scores, zeros)\n\n\ndef remove_borders(keypoints, scores, border: int, height: int, width: int):\n    \"\"\"Removes keypoints too close to the border.\"\"\"\n    mask_h = (keypoints[:, 0] >= border) & (keypoints[:, 0] < (height - border))\n    mask_w = (keypoints[:, 1] >= border) & (keypoints[:, 1] < (width - border))\n    mask = mask_h & mask_w\n    return keypoints[mask], scores[mask]\n\n\ndef top_k_keypoints(keypoints, scores, k: int):\n    if k >= len(keypoints):\n        return keypoints, scores\n    scores, indices = torch.topk(scores, k, dim=0)\n    return keypoints[indices], scores\n\n\ndef sample_descriptors(keypoints, descriptors, s: int = 8):\n    \"\"\"Interpolate descriptors at keypoint locations.\"\"\"\n    b, c, h, w = descriptors.shape\n    keypoints = keypoints - s / 2 + 0.5\n    keypoints /= torch.tensor([(w * s - s / 2 - 0.5), (h * s - s / 2 - 0.5)],).to(\n        keypoints\n    )[None]\n    keypoints = keypoints * 2 - 1  # normalize to (-1, 1)\n    args = {\"align_corners\": True} if torch.__version__ >= \"1.3\" else {}\n    descriptors = torch.nn.functional.grid_sample(\n        descriptors, keypoints.view(b, 1, -1, 2), mode=\"bilinear\", **args\n    )\n    descriptors = torch.nn.functional.normalize(\n        descriptors.reshape(b, c, -1), p=2, dim=1\n    )\n    return descriptors\n\n\nclass SuperPoint(nn.Module):\n    \"\"\"SuperPoint Convolutional Detector and Descriptor.\n\n    SuperPoint: Self-Supervised Interest Point Detection and\n    Description. Daniel DeTone, Tomasz Malisiewicz, and Andrew\n    Rabinovich. In CVPRW, 2019. https://arxiv.org/abs/1712.07629\n\n    \"\"\"\n\n    default_config = {\n        \"descriptor_dim\": 256,\n        \"nms_radius\": 4,\n        \"keypoint_threshold\": 0.005,\n        \"max_keypoints\": -1,\n        \"remove_borders\": 4,\n    }\n\n    def __init__(self, config):\n        super().__init__()\n        self.config = {**self.default_config, **config}\n\n        self.relu = nn.ReLU(inplace=True)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        c1, c2, c3, c4, c5 = 64, 64, 128, 128, 256\n\n        self.conv1a = nn.Conv2d(1, c1, kernel_size=3, stride=1, padding=1)\n        self.conv1b = nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n        self.conv2a = nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n        self.conv2b = nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n        self.conv3a = nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n        self.conv3b = nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n        self.conv4a = nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n        self.conv4b = nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n\n        self.convPa = nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n        self.convPb = nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n\n        self.convDa = nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n        self.convDb = nn.Conv2d(\n            c5, self.config[\"descriptor_dim\"], kernel_size=1, stride=1, padding=0\n        )\n\n        path = Path(__file__).parent / \"weights/superpoint_v1.pth\"\n        self.load_state_dict(torch.load(str(path)))\n\n        mk = self.config[\"max_keypoints\"]\n        if mk == 0 or mk < -1:\n            raise ValueError('\"max_keypoints\" must be positive or \"-1\"')\n\n        print(\"Loaded SuperPoint model\")\n\n    def forward(self, data):\n        \"\"\"Compute keypoints, scores, descriptors for image.\"\"\"\n        # Shared Encoder\n        x = self.relu(self.conv1a(data[\"image\"]))\n        x = self.relu(self.conv1b(x))\n        x = self.pool(x)\n        x = self.relu(self.conv2a(x))\n        x = self.relu(self.conv2b(x))\n        x = self.pool(x)\n        x = self.relu(self.conv3a(x))\n        x = self.relu(self.conv3b(x))\n        x = self.pool(x)\n        x = self.relu(self.conv4a(x))\n        x = self.relu(self.conv4b(x))\n\n        # Compute the dense keypoint scores\n        cPa = self.relu(self.convPa(x))\n        scores = self.convPb(cPa)\n        scores = torch.nn.functional.softmax(scores, 1)[:, :-1]\n        b, _, h, w = scores.shape\n        scores = scores.permute(0, 2, 3, 1).reshape(b, h, w, 8, 8)\n        scores = scores.permute(0, 1, 3, 2, 4).reshape(b, h * 8, w * 8)\n        scores = simple_nms(scores, self.config[\"nms_radius\"])\n\n        # Extract keypoints\n        keypoints = [\n            torch.nonzero(s > self.config[\"keypoint_threshold\"]) for s in scores\n        ]\n        scores = [s[tuple(k.t())] for s, k in zip(scores, keypoints)]\n\n        # Discard keypoints near the image borders\n        keypoints, scores = list(\n            zip(\n                *[\n                    remove_borders(k, s, self.config[\"remove_borders\"], h * 8, w * 8)\n                    for k, s in zip(keypoints, scores)\n                ]\n            )\n        )\n\n        # Keep the k keypoints with highest score\n        if self.config[\"max_keypoints\"] >= 0:\n            keypoints, scores = list(\n                zip(\n                    *[\n                        top_k_keypoints(k, s, self.config[\"max_keypoints\"])\n                        for k, s in zip(keypoints, scores)\n                    ]\n                )\n            )\n\n        # Convert (h, w) to (x, y)\n        keypoints = [torch.flip(k, [1]).float() for k in keypoints]\n\n        # Compute the dense descriptors\n        cDa = self.relu(self.convDa(x))\n        descriptors = self.convDb(cDa)\n        descriptors = torch.nn.functional.normalize(descriptors, p=2, dim=1)\n\n        # Extract descriptors\n        descriptors = [\n            sample_descriptors(k[None], d[None], 8)[0]\n            for k, d in zip(keypoints, descriptors)\n        ]\n\n        return {\n            \"keypoints\": keypoints,\n            \"scores\": scores,\n            \"descriptors\": descriptors,\n        }","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:39:03.72333Z","iopub.execute_input":"2024-08-06T08:39:03.723806Z","iopub.status.idle":"2024-08-06T08:39:05.856171Z","shell.execute_reply.started":"2024-08-06T08:39:03.723766Z","shell.execute_reply":"2024-08-06T08:39:05.855056Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\nfrom wildlife_tools.features.base import FeatureExtractor\n# from wildlife_tools.features.models.superpoint import SuperPoint\n\n\nclass SuperPointFeatures(FeatureExtractor):\n    def __init__(\n        self,\n        descriptor_dim: int = 256,\n        max_keypoints: int | None = None,\n        nms_radius: int = 4,\n        keypoint_threshold: float = 0.005,\n        remove_borders: int = 4,\n        device: str = \"cpu\",\n        num_workers: int = 1,\n        batch_size: int = 128,\n    ):\n        self.descriptor_dim = descriptor_dim\n        self.max_keypoints = max_keypoints\n        self.nms_radius = nms_radius\n        self.keypoint_threshold = keypoint_threshold\n        self.remove_borders = remove_borders\n        self.device = device\n        self.num_workers = num_workers\n        self.batch_size = batch_size\n\n    def __call__(self, dataset):\n        if not self.max_keypoints:\n            max_keypoints = -1\n        else:\n            max_keypoints = self.max_keypoints\n\n        model = SuperPoint(\n            config={\n                \"descriptor_dim\": self.descriptor_dim,\n                \"nms_radius\": self.nms_radius,\n                \"keypoint_threshold\": self.keypoint_threshold,\n                \"max_keypoints\": max_keypoints,\n                \"remove_borders\": self.remove_borders,\n            }\n        ).to(self.device)\n        loader = torch.utils.data.DataLoader(\n            dataset,\n            num_workers=self.num_workers,\n            batch_size=self.batch_size,\n            shuffle=False,\n        )\n\n        descriptors = []\n        for image, label in tqdm(loader, mininterval=1, ncols=100):\n            with torch.no_grad():\n                output = model({\"image\": image.to(self.device)})\n            descriptors.extend(\n                [d.permute(1, 0).cpu().numpy() for d in output[\"descriptors\"]]\n            )\n        return descriptors","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:39:35.910503Z","iopub.execute_input":"2024-08-06T08:39:35.911086Z","iopub.status.idle":"2024-08-06T08:39:35.926885Z","shell.execute_reply.started":"2024-08-06T08:39:35.911045Z","shell.execute_reply":"2024-08-06T08:39:35.925285Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# from wildlife_tools.features import  SuperPointFeatures\nimport wildlife_tools.features\nhelp(wildlife_tools.features)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:39:59.650113Z","iopub.execute_input":"2024-08-06T08:39:59.650584Z","iopub.status.idle":"2024-08-06T08:39:59.659321Z","shell.execute_reply.started":"2024-08-06T08:39:59.650549Z","shell.execute_reply":"2024-08-06T08:39:59.657948Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Help on package wildlife_tools.features in wildlife_tools:\n\nNAME\n    wildlife_tools.features\n\nPACKAGE CONTENTS\n    base\n    deep\n    memory\n    sift\n    superpoint\n\nFILE\n    /opt/conda/lib/python3.10/site-packages/wildlife_tools/features/__init__.py\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"f = open(\"/opt/conda/lib/python3.10/site-packages/wildlife_tools/features/__init__.py\", \"r\")\nf.read()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:44:15.123737Z","iopub.execute_input":"2024-08-06T08:44:15.124219Z","iopub.status.idle":"2024-08-06T08:44:15.136355Z","shell.execute_reply.started":"2024-08-06T08:44:15.124185Z","shell.execute_reply":"2024-08-06T08:44:15.134445Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'from .deep import ClipFeatures, DeepFeatures\\nfrom .memory import DataToMemory\\nfrom .sift import SIFTFeatures\\n\\n# from .superpoint import SuperPointFeatures #TODO: Fix import\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom wildlife_datasets import datasets\nfrom wildlife_tools.data import WildlifeDataset\nfrom wildlife_tools.features import SIFTFeatures\nimport cv2  # Import OpenCV for SIFT\n\n\n\n# Download dataset (if not already downloaded)\ndatasets.CZoo.get_data('../data/CZoo')\n\n# Load dataset metadata\nmetadata_CZoo = datasets.CZoo('../data/CZoo')\n\n# Define transformations: resize, convert to PIL Image, convert to grayscale, and convert to numpy array\ntransform = T.Compose([\n    T.Resize([224, 224]),  # Resize the image\n    # T.ToPILImage(),  # Convert tensor to PIL Image\n    T.Grayscale(),  # Convert to grayscale\n    # T.ToTensor(),  # Convert PIL Image to numpy array\n    # lambda x: (x * 255).astype(np.uint8)  # Convert to 8-bit integer format\n])\n\n# Create datasets with transformations\ndataset = WildlifeDataset(metadata_CZoo.df, metadata_CZoo.root, transform=transform)\ndataset_database_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[100:], metadata_CZoo.root, transform=transform)\ndataset_query_CZoo = WildlifeDataset(metadata_CZoo.df.iloc[:100], metadata_CZoo.root, transform=transform)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:45:35.701991Z","iopub.execute_input":"2024-08-06T08:45:35.702575Z","iopub.status.idle":"2024-08-06T08:46:03.400493Z","shell.execute_reply.started":"2024-08-06T08:45:35.702535Z","shell.execute_reply":"2024-08-06T08:46:03.398751Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"DATASET CZoo: DOWNLOADING STARTED.\n","output_type":"stream"},{"name":"stderr","text":"master.zip: 634MB [00:21, 29.2MB/s] \n","output_type":"stream"},{"name":"stdout","text":"DATASET CZoo: EXTRACTING STARTED.\nDATASET CZoo: FINISHED.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initialize SIFT extractor\nsift = cv2.SIFT_create()\nextractor_CZoo =  SuperPointFeatures()\n\nquery_CZoo, database_CZoo = extractor_CZoo(dataset_query_CZoo), extractor_CZoo(dataset_database_CZoo)\n\nprint(f'First 5 query features shape: {[i.shape for i in query_CZoo[:5]]}')\nprint(f'First 5 database features shape: {[i.shape for i in database_CZoo[:5]]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:47:14.429792Z","iopub.execute_input":"2024-08-06T08:47:14.430428Z","iopub.status.idle":"2024-08-06T08:47:14.671212Z","shell.execute_reply.started":"2024-08-06T08:47:14.430382Z","shell.execute_reply":"2024-08-06T08:47:14.66906Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sift \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mSIFT_create()\n\u001b[1;32m      3\u001b[0m extractor_CZoo \u001b[38;5;241m=\u001b[39m  SuperPointFeatures()\n\u001b[0;32m----> 5\u001b[0m query_CZoo, database_CZoo \u001b[38;5;241m=\u001b[39m \u001b[43mextractor_CZoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_query_CZoo\u001b[49m\u001b[43m)\u001b[49m, extractor_CZoo(dataset_database_CZoo)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst 5 query features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[i\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mi\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mquery_CZoo[:\u001b[38;5;241m5\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst 5 database features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[i\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mi\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mdatabase_CZoo[:\u001b[38;5;241m5\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mSuperPointFeatures.__call__\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     max_keypoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_keypoints\n\u001b[0;32m---> 35\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSuperPoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescriptor_dim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescriptor_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnms_radius\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms_radius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeypoint_threshold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeypoint_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_keypoints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_keypoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mremove_borders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove_borders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     44\u001b[0m loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     45\u001b[0m     dataset,\n\u001b[1;32m     46\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m     47\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     48\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m descriptors \u001b[38;5;241m=\u001b[39m []\n","Cell \u001b[0;32mIn[4], line 143\u001b[0m, in \u001b[0;36mSuperPoint.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvDa \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(c4, c5, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvDb \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\n\u001b[1;32m    140\u001b[0m     c5, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescriptor_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m], kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 143\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/superpoint_v1.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mstr\u001b[39m(path)))\n\u001b[1;32m    146\u001b[0m mk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_keypoints\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"],"ename":"NameError","evalue":"name '__file__' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import timm\nimport pandas as pd\nimport torchvision.transforms as T\n\nfrom wildlife_tools.data import WildlifeDataset, SplitMetadata\nfrom wildlife_tools.features import SIFTFeatures\nfrom wildlife_tools.similarity import MatchDescriptors\nfrom wildlife_tools.inference import KnnClassifier\n\nsimilarity = MatchDescriptors(descriptor_dim=128, thresholds=[0.8])\nsim = similarity(query_CZoo, database_CZoo)[0.8]\n\nprint(\"Number of SIFT correspondences after 0.8 ratio test threshold: \\n\", sim)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_CZoo = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npredictions_CZoo = classifier_CZoo(sim)\nprint(\"Predictions for 100 test Images:-\\n\",predictions_CZoo)\n\naccuracy_CZoo = np.mean(dataset_query_CZoo.labels_string == predictions_CZoo)\nprint(\"Accuracy on CZoo data: {:.2f}%\".format(accuracy_CZoo * 100))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest neigbour classifier using the similarity\nclassifier = KnnClassifier(k=1, database_labels=dataset_database_CZoo.labels_string)\npreds = classifier(sim)\nprint(\"Prediction \\t\", preds)\nprint(\"Ground truth \\t\", dataset_query_CZoo.labels_string)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = sum(preds == dataset_query_CZoo.labels_string) / len(dataset_query_CZoo.labels_string)\nprint('\\n Accuracy: ', acc*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]}]}